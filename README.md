[![APGarchev](https://circleci.com/gh/APGarchev/ml-microservice-kubernetes.svg?style=svg)](https://circleci.com/gh/APGarchev/ml-microservice-kubernetes)

## Project Overview

In this project, you will apply the skills you have acquired in this course to operationalize a Machine Learning Microservice API.

You are given a pre-trained, `sklearn` model that has been trained to predict housing prices in Boston according to several features, such as average rooms in a home and data about highway access, teacher-to-pupil ratios, and so on. You can read more about the data, which was initially taken from Kaggle, on [the data source site](https://www.kaggle.com/c/boston-housing). This project tests your ability to operationalize a Python flask app—in a provided file, `app.py`—that serves out predictions (inference) about housing prices through API calls. This project could be extended to any pre-trained machine learning model, such as those for image recognition and data labeling.

---

## Setup the Environment

- Create a Python 3.7 virtual environment and activate it
- Run `make install` to install the necessary dependencies

### Running `app.py`

1. Standalone: `python app.py`
2. Run in Docker: `./run_docker.sh <DOCKER_ID> <DOCKER_IMAGE>`
3. Run in Kubernetes: `./run_kubernetes.sh <DOCKER_ID> <DOCKER_IMAGE>`

To run the application in Docker and Kubernetes you must provide Docker account and image that contains an application image.

#### Examples

`
./run_docker.sh apgarchev ml-microservice

./run_kubernetes.sh apgarchev ml-microservice
`

### Running a Prediction

Execute the script `./make_prediction.sh` to send a HTTP Post request to the application with all needed parameters to create a prediction.

### Stoping Application

To stop the application that was ran in Docker by `run_docker.sh` script you must execute the command `docker kill <DOCKER_IMAGE>`. The parameter `<DOCKER_IMAGE>` is used to tag the created Docker container by `run_docker.sh`.

#### Example

`docker kill ml-microservice`

To stop the application that was run in Kubernetes by `run_kubernetes.sh` script you must execute the command `docker stack rm ml-app` and terminate the port forwarding, too.

### Upload Docker Image to Docker Repository

Run the `./upload_docker.sh <DOCKER_ID> <DOCKER_IMAGE>`. That script gets the Docker image of the application that must have already been built and upload it to the Docker repository.

#### Example

`./upload_docker.sh apgarchev ml-microservice`

### Repository Description

The repository contains the following files and directories:

1. `app.py`: that is the main application file;
2. `Dockerfile`: that file is being used to create a Docker image;
3. `make_prediction.sh`: a script that sends HTTP Post request to the application to create a prediciton;
4. `Makefile`: that is a script file that contains utility directives/rules to run, compile and lint the application more efficiently;
5. `requirements.txt`: list of Python packages needed to build the application;
6. `run_docker.sh`: that is a script that automates the application running in Docker;
7. `run_kubernetes.sh`: that is a script that automates the application running in Kubernetes;
8. `upload_docker.sh`: that is a script that uploads the application image to Docker repository;
9. `model_data directory`: that directory contains files needed to load the pre-trained, `sklearn` model;
10. `.circleci directory`: that direcorty contains configuration file `config.yml` needed to run CircleCI automation process;
11. `output_txt_files directory`: that directory contains example of logs generated by the application that runs in Docker and Kubernetes.
